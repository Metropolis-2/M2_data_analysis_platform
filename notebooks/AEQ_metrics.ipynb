{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from loguru import logger\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "from config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CONF_LOG_PREFIX = 'CONFLOG'\n",
    "FLST_LOG_PREFIX = 'FLSTLOG'\n",
    "GEO_LOG_PREFIX = 'GEOLOG'\n",
    "LOS_LOG_PREFIX = 'LOSLOG'\n",
    "REG_LOG_PREFIX = 'REGLOG'\n",
    "LOADING_PATH = '/mnt/shared/repos/metropolis/M2_data_analysis_platform/output'\n",
    "DATAFRAMES_NAMES = [CONF_LOG_PREFIX, FLST_LOG_PREFIX, GEO_LOG_PREFIX, LOS_LOG_PREFIX, REG_LOG_PREFIX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(Path(Path().absolute().parent, 'platform_code')))\n",
    "from schemas.tables_attributes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataframes(files_names: List[str], loading_path: str, spark: SparkSession) -> Dict[str, DataFrame]:\n",
    "    \"\"\" Loads the dataframes which macht the file names passed by arguments.\n",
    "    The method read from the config the path were to read the files, which\n",
    "    matches the folder where the files are saved in `save_dataframes_dict()`.\n",
    "\n",
    "    :param files_names: list of the names of the files.\n",
    "    :param loading_path: path were the files are saved.\n",
    "    :param spark: spark session.\n",
    "    :return: dictionary with the dataframes loaded from the files, with the\n",
    "     file name as key.\n",
    "    \"\"\"\n",
    "    dataframes = dict()\n",
    "\n",
    "    for file_name in files_names:\n",
    "        file_path = Path(loading_path, f'{file_name.lower()}.parquet')\n",
    "        logger.info('Loading dataframe from `{}`.', file_path)\n",
    "        df = spark.read.parquet(str(file_path))\n",
    "        dataframes[file_name] = df\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Notebook').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 12:06:50.225 | INFO     | __main__:load_dataframes:16 - Loading dataframe from `/mnt/shared/repos/metropolis/M2_data_analysis_platform/output/conflog.parquet`.\n",
      "2022-03-25 12:06:55.596 | INFO     | __main__:load_dataframes:16 - Loading dataframe from `/mnt/shared/repos/metropolis/M2_data_analysis_platform/output/flstlog.parquet`.\n",
      "2022-03-25 12:06:55.881 | INFO     | __main__:load_dataframes:16 - Loading dataframe from `/mnt/shared/repos/metropolis/M2_data_analysis_platform/output/geolog.parquet`.\n",
      "2022-03-25 12:06:56.081 | INFO     | __main__:load_dataframes:16 - Loading dataframe from `/mnt/shared/repos/metropolis/M2_data_analysis_platform/output/loslog.parquet`.\n",
      "2022-03-25 12:06:56.284 | INFO     | __main__:load_dataframes:16 - Loading dataframe from `/mnt/shared/repos/metropolis/M2_data_analysis_platform/output/reglog.parquet`.\n"
     ]
    }
   ],
   "source": [
    "input_dataframes = load_dataframes(DATAFRAMES_NAMES, LOADING_PATH, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = input_dataframes[FLST_LOG_PREFIX].select(SCENARIO_NAME, PRIORITY, LOITERING, BASELINE_ARRIVAL_TIME,\n",
    "                                                     DEL_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.withColumn(\"delay\", col(DEL_TIME) - col(BASELINE_ARRIVAL_TIME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+---------+---------------------+-------------+-------------------+\n",
      "|          Scenario|Priority|loitering|Baseline_arrival_time|Deletion_Time|              delay|\n",
      "+------------------+--------+---------+---------------------+-------------+-------------------+\n",
      "|1_very_low_40_8_W1|       3|    false|    93.58550517846484|        128.0|  34.41449482153516|\n",
      "|1_very_low_40_8_W1|       2|    false|   234.92153759118554|        199.0| -35.92153759118554|\n",
      "|1_very_low_40_8_W1|       3|    false|   194.43859065760762|        206.5|  12.06140934239238|\n",
      "|1_very_low_40_8_W1|       2|    false|   153.96310445561087|        221.5|  67.53689554438913|\n",
      "|1_very_low_40_8_W1|       3|    false|   191.42273558168245|        245.5| 54.077264418317554|\n",
      "|1_very_low_40_8_W1|       1|    false|   207.18630252338767|        250.5|  43.31369747661233|\n",
      "|1_very_low_40_8_W1|       3|    false|    184.8503295284063|        252.5|  67.64967047159371|\n",
      "|1_very_low_40_8_W1|       1|    false|   267.02498015434514|        263.0| -4.024980154345144|\n",
      "|1_very_low_40_8_W1|       1|    false|    194.1596341580672|        273.0|   78.8403658419328|\n",
      "|1_very_low_40_8_W1|       2|    false|   240.50303275357163|        284.0|  43.49696724642837|\n",
      "|1_very_low_40_8_W1|       2|    false|     219.278887841879|        301.0|    81.721112158121|\n",
      "|1_very_low_40_8_W1|       1|    false|   243.79275574372926|        301.5|  57.70724425627074|\n",
      "|1_very_low_40_8_W1|       2|    false|    419.4987550112725|        304.5|-114.99875501127252|\n",
      "|1_very_low_40_8_W1|       2|    false|   222.28694374236704|        314.5|  92.21305625763296|\n",
      "|1_very_low_40_8_W1|       3|    false|   186.79625520135951|        318.0| 131.20374479864049|\n",
      "|1_very_low_40_8_W1|       1|    false|    279.3119790107202|        325.0|  45.68802098927978|\n",
      "|1_very_low_40_8_W1|       2|    false|   218.33340086209196|        326.0| 107.66659913790804|\n",
      "|1_very_low_40_8_W1|       1|    false|   275.42384956159617|        326.5|  51.07615043840383|\n",
      "|1_very_low_40_8_W1|       2|    false|    264.7516326637668|        339.0|  74.24836733623317|\n",
      "|1_very_low_40_8_W1|       1|    false|    324.3150947427846|        340.0| 15.684905257215405|\n",
      "+------------------+--------+---------+---------------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.withColumn(\"cancelation_limit\",\n",
    "                                 when(col(PRIORITY) == 4, settings.thresholds.emergency_mission_delay)\n",
    "                                 .otherwise(when(col(LOITERING), settings.thresholds.loitering_mission_delay)\n",
    "                                            .otherwise(settings.thresholds.delivery_mission_delay)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.select(SCENARIO_NAME, PRIORITY, LOITERING, \"delay\", \"cancelation_limit\").withColumn(\n",
    "    \"cancelled_demand\", col(\"delay\") >= col(\"cancelation_limit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.select(SCENARIO_NAME, \"cancelled_demand\").where(col(\"cancelled_demand\")).groupby(\n",
    "    SCENARIO_NAME).count().withColumnRenamed(\"count\", \"AEQ1\")\n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.select(AEQ1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe2 = input_dataframes[FLST_LOG_PREFIX].select(SCENARIO_NAME, ACID)\n",
    "dataframe2 = dataframe2.groupby(SCENARIO_NAME).count().withColumnRenamed(\"count\", \"Num_Acids\")\n",
    "dataframe2 = dataframe2.join(dataframe, on=[SCENARIO_NAME], how='outer')\n",
    "dataframe2 = dataframe2.withColumn(AEQ2, (col(AEQ1) / col(\"Num_Acids\")) * 100).select(SCENARIO_NAME, AEQ2)\n",
    "dataframe2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.join(df2, on=[SCENARIO_NAME], how='outer')\n",
    "df3 = df3.withColumn(\"AEQ2\", (col(\"AEQ1\") / col(\"Num_Acids\")) * 100).select(SCENARIO_NAME, AEQ2)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataframes[FLST_LOG_PREFIX].select(SCENARIO_NAME, ACID).groupby(SCENARIO_NAME).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataframes[FLST_LOG_PREFIX].select(SCENARIO_NAME, PRIORITY, LOITERING, \"delay\", PRIORITY, LOITERING).(\n",
    "    (col(PRIORITY) == 4) | (col(LOITERING))).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe3 = input_dataframes[FLST_LOG_PREFIX].select(SCENARIO_NAME, ACID, FLIGHT_TIME, VEHICLE)\n",
    "dataframe3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe3 = input_dataframes[FLST_LOG_PREFIX].withColumn(\"autonomy\",\n",
    "                                                          when(col(VEHICLE) == \"MP20\", settings.MP20.autonomy)\n",
    "                                                          .otherwise(settings.MP30.autonomy))\n",
    "\n",
    "dataframe3 = dataframe3.select(SCENARIO_NAME, ACID, FLIGHT_TIME, VEHICLE, \"autonomy\")\n",
    "dataframe3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe3 = dataframe3.withColumn(\"inoperative\", when(col(FLIGHT_TIME) >= col(\"autonomy\"), True).otherwise(False))\n",
    "dataframe3 = dataframe3.select(SCENARIO_NAME, col(\"inoperative\")).where(col(\"inoperative\") == True).groupby(\n",
    "    SCENARIO_NAME).count().withColumnRenamed(\"count\", AEQ2)\n",
    "dataframe3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|          Scenario|         avg_delay|\n",
      "+------------------+------------------+\n",
      "|1_very_low_40_8_W1|174.88071918752135|\n",
      "|3_very_low_40_8_W1|174.88071918752135|\n",
      "|2_very_low_40_8_W1|174.88071918752135|\n",
      "|3_very_low_40_8_R2|174.88071918752135|\n",
      "|1_very_low_40_8_R2|174.88071918752135|\n",
      "|2_very_low_40_8_R2|174.88071918752135|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, mean\n",
    "\n",
    "avg_delay = input_dataframes[FLST_LOG_PREFIX].select(SCENARIO_NAME, BASELINE_ARRIVAL_TIME, DEL_TIME) \\\n",
    "    .groupby(SCENARIO_NAME) \\\n",
    "    .agg(mean(col(DEL_TIME) - col(BASELINE_ARRIVAL_TIME)).alias(\"avg_delay\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         avg_delay|\n",
      "+------------------+\n",
      "|174.88071918752118|\n",
      "+------------------+\n",
      "\n",
      "+------------------+---------------------+-------------+-------------------+------------------+------------------+\n",
      "|          Scenario|Baseline_arrival_time|Deletion_Time|              delay|         avg_delay|   delay_increment|\n",
      "+------------------+---------------------+-------------+-------------------+------------------+------------------+\n",
      "|1_very_low_40_8_W1|    93.58550517846484|        128.0|  34.41449482153516|174.88071918752118|140.46622436598602|\n",
      "|1_very_low_40_8_W1|   234.92153759118554|        199.0| -35.92153759118554|174.88071918752118|210.80225677870672|\n",
      "|1_very_low_40_8_W1|   194.43859065760762|        206.5|  12.06140934239238|174.88071918752118| 162.8193098451288|\n",
      "|1_very_low_40_8_W1|   153.96310445561087|        221.5|  67.53689554438913|174.88071918752118|107.34382364313205|\n",
      "|1_very_low_40_8_W1|   191.42273558168245|        245.5| 54.077264418317554|174.88071918752118|120.80345476920363|\n",
      "|1_very_low_40_8_W1|   207.18630252338767|        250.5|  43.31369747661233|174.88071918752118|131.56702171090885|\n",
      "|1_very_low_40_8_W1|    184.8503295284063|        252.5|  67.64967047159371|174.88071918752118|107.23104871592747|\n",
      "|1_very_low_40_8_W1|   267.02498015434514|        263.0| -4.024980154345144|174.88071918752118|178.90569934186632|\n",
      "|1_very_low_40_8_W1|    194.1596341580672|        273.0|   78.8403658419328|174.88071918752118| 96.04035334558839|\n",
      "|1_very_low_40_8_W1|   240.50303275357163|        284.0|  43.49696724642837|174.88071918752118| 131.3837519410928|\n",
      "|1_very_low_40_8_W1|     219.278887841879|        301.0|    81.721112158121|174.88071918752118| 93.15960702940018|\n",
      "|1_very_low_40_8_W1|   243.79275574372926|        301.5|  57.70724425627074|174.88071918752118|117.17347493125044|\n",
      "|1_very_low_40_8_W1|    419.4987550112725|        304.5|-114.99875501127252|174.88071918752118| 289.8794741987937|\n",
      "|1_very_low_40_8_W1|   222.28694374236704|        314.5|  92.21305625763296|174.88071918752118| 82.66766292988822|\n",
      "|1_very_low_40_8_W1|   186.79625520135951|        318.0| 131.20374479864049|174.88071918752118|43.676974388880694|\n",
      "|1_very_low_40_8_W1|    279.3119790107202|        325.0|  45.68802098927978|174.88071918752118| 129.1926981982414|\n",
      "|1_very_low_40_8_W1|   218.33340086209196|        326.0| 107.66659913790804|174.88071918752118| 67.21412004961314|\n",
      "|1_very_low_40_8_W1|   275.42384956159617|        326.5|  51.07615043840383|174.88071918752118|123.80456874911735|\n",
      "|1_very_low_40_8_W1|    264.7516326637668|        339.0|  74.24836733623317|174.88071918752118|  100.632351851288|\n",
      "|1_very_low_40_8_W1|    324.3150947427846|        340.0| 15.684905257215405|174.88071918752118|159.19581393030577|\n",
      "+------------------+---------------------+-------------+-------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------------+-----------------+\n",
      "|          Scenario|             AEQ4|\n",
      "+------------------+-----------------+\n",
      "|1_very_low_40_8_W1|954.8704689213282|\n",
      "|3_very_low_40_8_W1|954.8704689213282|\n",
      "|2_very_low_40_8_W1|954.8704689213282|\n",
      "|3_very_low_40_8_R2|954.8704689213282|\n",
      "|1_very_low_40_8_R2|954.8704689213282|\n",
      "|2_very_low_40_8_R2|954.8704689213282|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "from pyspark.sql.functions import abs\n",
    "\n",
    "dataframe4 = input_dataframes[FLST_LOG_PREFIX].select(SCENARIO_NAME, BASELINE_ARRIVAL_TIME, DEL_TIME)\n",
    "dataframe4 = dataframe4.withColumn(\"delay\", (col(DEL_TIME) - col(BASELINE_ARRIVAL_TIME)))\n",
    "avg_delay = dataframe4.select(mean(\"delay\").alias(\"avg_delay\"))\n",
    "avg_delay.show()\n",
    "dataframe4 = dataframe4.join(avg_delay, how='outer')\n",
    "dataframe4 = dataframe4.withColumn(\"delay_increment\", abs(col(\"delay\") - col(\"avg_delay\")))\n",
    "dataframe4.show()\n",
    "dataframe4 = dataframe4.groupby(SCENARIO_NAME).agg(F.max(\"delay_increment\").alias(AEQ4))\n",
    "dataframe4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe5 = input_dataframes[FLST_LOG_PREFIX].select(SCENARIO_NAME, ACID, BASELINE_ARRIVAL_TIME, DEL_TIME)\n",
    "dataframe5 = dataframe5.withColumn(\"delay\", (col(DEL_TIME) - col(BASELINE_ARRIVAL_TIME)))\n",
    "avg_delay = dataframe5.select(mean(\"delay\").alias(\"avg_delay\"))\n",
    "avg_delay.show()\n",
    "dataframe5 = dataframe5.join(avg_delay, how='outer')\n",
    "dataframe5.show()\n",
    "dataframe5.select(SCENARIO_NAME, ACID).where(\n",
    "    (col(\"delay\") > col(\"avg_delay\") + 5) | (col(\"delay\") < col(\"avg_delay\") - 5)).groupby(\n",
    "    SCENARIO_NAME).count().withColumnRenamed(\"count\", AEQ5).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import stddev\n",
    "\n",
    "dataframe6 = input_dataframes[FLST_LOG_PREFIX].select(SCENARIO_NAME, ACID, BASELINE_ARRIVAL_TIME, DEL_TIME)\n",
    "dataframe6 = dataframe6.groupby(SCENARIO_NAME).agg(stddev(col(DEL_TIME) - col(BASELINE_ARRIVAL_TIME)).alias(AEQ3))\n",
    "dataframe6.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}