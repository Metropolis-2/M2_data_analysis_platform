{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "from loguru import logger\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import udf, col, when\n",
    "import geopy.distance\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "from geopy.distance import great_circle\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import lit, struct\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import pow, col, log\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CONF_LOG_PREFIX = 'CONFLOG'\n",
    "FLST_LOG_PREFIX = 'FLSTLOG'\n",
    "GEO_LOG_PREFIX = 'GEOLOG'\n",
    "LOS_LOG_PREFIX = 'LOSLOG'\n",
    "REG_LOG_PREFIX = 'REGLOG'\n",
    "LOADING_PATH = '../output'\n",
    "DATAFRAMES_NAMES = [CONF_LOG_PREFIX, FLST_LOG_PREFIX, GEO_LOG_PREFIX, LOS_LOG_PREFIX, REG_LOG_PREFIX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give access to the constants that defines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(str(Path(Path().absolute().parent, 'platform_code')))\n",
    "from schemas.tables_attributes import *\n",
    "from utils.config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataframes(files_names: List[str], loading_path: str, spark: SparkSession) -> Dict[str, DataFrame]:\n",
    "    \"\"\" Loads the dataframes which macht the file names passed by arguments.\n",
    "    The method read from the config the path were to read the files, which\n",
    "    matches the folder where the files are saved in `save_dataframes_dict()`.\n",
    "\n",
    "    :param files_names: list of the names of the files.\n",
    "    :param loading_path: path were the files are saved.\n",
    "    :param spark: spark session.\n",
    "    :return: dictionary with the dataframes loaded from the files, with the\n",
    "     file name as key.\n",
    "    \"\"\"\n",
    "    dataframes = dict()\n",
    "\n",
    "    for file_name in files_names:\n",
    "        file_path = Path(loading_path, f'{file_name.lower()}.parquet')\n",
    "        logger.info('Loading dataframe from `{}`.', file_path)\n",
    "        df = spark.read.parquet(str(file_path))\n",
    "        dataframes[file_name] = df\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Notebook').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 16:42:40.805 | INFO     | __main__:load_dataframes:16 - Loading dataframe from `..\\output\\conflog.parquet`.\n",
      "2022-04-04 16:42:43.794 | INFO     | __main__:load_dataframes:16 - Loading dataframe from `..\\output\\flstlog.parquet`.\n",
      "2022-04-04 16:42:43.921 | INFO     | __main__:load_dataframes:16 - Loading dataframe from `..\\output\\geolog.parquet`.\n",
      "2022-04-04 16:42:44.003 | INFO     | __main__:load_dataframes:16 - Loading dataframe from `..\\output\\loslog.parquet`.\n",
      "2022-04-04 16:42:44.092 | INFO     | __main__:load_dataframes:16 - Loading dataframe from `..\\output\\reglog.parquet`.\n"
     ]
    }
   ],
   "source": [
    "input_dataframes = load_dataframes(DATAFRAMES_NAMES, LOADING_PATH, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def get_coordinates_distance(origin_latitude: float, origin_longitude: float,\n",
    "                             destination_latitude: float, destination_longitude: float) -> float:\n",
    "    \"\"\" Calculates the distance in meters between two world coordinates.\n",
    "\n",
    "    :param origin_latitude: origin latitude point.\n",
    "    :param origin_longitude: origin longitude point.\n",
    "    :param destination_latitude: destination latitude point.\n",
    "    :param destination_longitude: destination longitude point.\n",
    "    :return: distance in meters.\n",
    "    \"\"\"\n",
    "    origin_tuple = (origin_latitude, origin_longitude)\n",
    "    destination_tuple = (destination_latitude, destination_longitude)\n",
    "    # TODO: direct distance calculation (in meters) between two points, is this approach correct?\n",
    "    return geopy.distance.distance(origin_tuple, destination_tuple).m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENV-2: Weighted average altitude\n",
    "Average flight level weighed by the length flown at each flight level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = input_dataframes[REG_LOG_PREFIX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we check the log for a given drone in a given scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#dataframe.where(col(SCENARIO_NAME) == '1_very_low_40_8_R2').where(col(ACID) == 'D1').orderBy(SIMULATION_TIME, ACID).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column with the next coordinates system for the same drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "window = Window.partitionBy(SCENARIO_NAME, ACID).orderBy(SIMULATION_TIME)\n",
    "next_step = dataframe.withColumn(\"NEXT_LATITUDE\",lag(LATITUDE, -1).over(window)).withColumn(\"NEXT_LONGITUDE\",lag(LONGITUDE, -1).over(window)).withColumn(\"NEXT_ALTITUDE\",lag(ALTITUDE, -1).over(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#next_step.where(col(SCENARIO_NAME) == '1_very_low_40_8_R2').where(col(ACID) == 'D1').show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with NEXT_LATITUDE and NEXT_LONGITUDE null (they are the rows of separation between scenarios)\n",
    "dataframe = next_step.na.drop(subset=[\"NEXT_LATITUDE\",\"NEXT_LONGITUDE\"])\n",
    "#Check it\n",
    "dataframe.filter(col(\"NEXT_LATITUDE\").isNull() | col(\"NEXT_LATITUDE\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.withColumn(\"SEGMENT_LENGTH\",get_coordinates_distance(LATITUDE, LONGITUDE, \"NEXT_LATITUDE\", \"NEXT_LONGITUDE\")).withColumn(\"SEGMENT_ALTITUDE\", (col(ALTITUDE)+col(\"NEXT_ALTITUDE\"))/2)\n",
    "dataframe = dataframe.withColumn(\"SEGMENT_WEIGHT\", col(\"SEGMENT_ALTITUDE\") * col(\"SEGMENT_LENGTH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe.select(REG_ID, SCENARIO_NAME, ACID, \"SEGMENT_LENGTH\", \"SEGMENT_ALTITUDE\", \"SEGMENT_WEIGHT\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.groupby(SCENARIO_NAME).agg(sum(col(\"SEGMENT_WEIGHT\")), sum(col(\"SEGMENT_LENGTH\"))).withColumn(ENV2, col(\"sum(SEGMENT_WEIGHT)\")/col(\"sum(SEGMENT_LENGTH)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+------------------+------------------+------------------+------------------+\n",
      "|          Scenario| ACID|      MAX_ALTITUDE|      MIN_ALTITUDE|     DIFF_ALTITUDE|MEAN_DIFF_ALTITUDE|\n",
      "+------------------+-----+------------------+------------------+------------------+------------------+\n",
      "|1_very_low_40_8_R2|D1351|            82.296|   41.389389999312|40.906610000688005|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D1652|   132.04138999848|             9.144|122.89738999848001|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D1740|           118.872|12.618610000728001|  106.253389999272|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D2171|  132.346610000688|             9.144|  123.202610000688|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D2311|  102.414609999936|             9.144|   93.270609999936|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D2366|           146.304|1.3893899994720003|  144.914610000528|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D2395|            82.296|            18.288| 64.00800000000001|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D2557|  136.185390000024|             9.144|  127.041390000024|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D2712| 59.98261000152001|22.313389998479998| 37.66922000304001|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D2752|            73.152|             9.144|            64.008|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D2708|            137.16|            18.288|           118.872|   78.248320994009|\n",
      "|1_very_low_40_8_R2|D2781|109.72800000000001|             9.144|           100.584|   78.248320994009|\n",
      "|1_very_low_40_8_W1|D1782|   35.050609999224|             9.144|25.906609999224003|   78.248320994009|\n",
      "|1_very_low_40_8_W1|D1923|            82.296|            3.1242|           79.1718|   78.248320994009|\n",
      "|1_very_low_40_8_W1|D2411|            73.152|               0.0|            73.152|   78.248320994009|\n",
      "|1_very_low_40_8_W1|D2503|           146.304|12.618610000728001|  133.685389999272|   78.248320994009|\n",
      "|1_very_low_40_8_W1|D2853|             45.72|             9.144|            36.576|   78.248320994009|\n",
      "|1_very_low_40_8_W1|D3023| 88.31580000000001|             9.144|           79.1718|   78.248320994009|\n",
      "|3_very_low_40_8_R2|D1034|            137.16|             9.144|           128.016|   78.248320994009|\n",
      "|3_very_low_40_8_R2|D1517|            82.296|32.618610000648005|   49.677389999352|   78.248320994009|\n",
      "+------------------+-----+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------------+-----+-------------------+\n",
      "|          Scenario| ACID|               ENV4|\n",
      "+------------------+-----+-------------------+\n",
      "|1_very_low_40_8_R2|D1351| 0.5227793961715801|\n",
      "|1_very_low_40_8_R2|D1652|  1.570607374538931|\n",
      "|1_very_low_40_8_R2|D1740| 1.3578999350977405|\n",
      "|1_very_low_40_8_R2|D2171|  1.574508033343244|\n",
      "|1_very_low_40_8_R2|D2311| 1.1919822536138143|\n",
      "|1_very_low_40_8_R2|D2366| 1.8519836356823967|\n",
      "|1_very_low_40_8_R2|D2395| 0.8180111622446277|\n",
      "|1_very_low_40_8_R2|D2557|  1.623566977363652|\n",
      "|1_very_low_40_8_R2|D2712|0.48140611229120317|\n",
      "|1_very_low_40_8_R2|D2752| 0.8180111622446276|\n",
      "|1_very_low_40_8_R2|D2708|  1.519163587025737|\n",
      "|1_very_low_40_8_R2|D2781| 1.2854461120987006|\n",
      "|1_very_low_40_8_W1|D1782| 0.3310819921772828|\n",
      "|1_very_low_40_8_W1|D1923| 1.0118019018716287|\n",
      "|1_very_low_40_8_W1|D2411| 0.9348698997081458|\n",
      "|1_very_low_40_8_W1|D2503|  1.708476147488295|\n",
      "|1_very_low_40_8_W1|D2853| 0.4674349498540729|\n",
      "|1_very_low_40_8_W1|D3023| 1.0118019018716287|\n",
      "|3_very_low_40_8_R2|D1034|  1.636022324489255|\n",
      "|3_very_low_40_8_R2|D1517| 0.6348684466105732|\n",
      "+------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ENV4\n",
    "dataframe4 = input_dataframes[REG_LOG_PREFIX]\n",
    "dataframe4 = dataframe4.groupby(SCENARIO_NAME, ACID).agg(F.max(ALTITUDE).alias(\"MAX_ALTITUDE\"), F.min(ALTITUDE).alias(\"MIN_ALTITUDE\"))\n",
    "dataframe4 = dataframe4.withColumn(\"DIFF_ALTITUDE\", col(\"MAX_ALTITUDE\") - col(\"MIN_ALTITUDE\"))\n",
    "avg_delay = dataframe4.select(mean(\"DIFF_ALTITUDE\").alias(\"MEAN_DIFF_ALTITUDE\"))\n",
    "dataframe4 = dataframe4.join(avg_delay, how='outer')\n",
    "dataframe4.show()\n",
    "\n",
    "dataframe4 = dataframe4.withColumn(ENV4, col(\"DIFF_ALTITUDE\")/col(\"MEAN_DIFF_ALTITUDE\"))\n",
    "dataframe4 = dataframe4.select(SCENARIO_NAME, ACID, ENV4)\n",
    "dataframe4.show()\n",
    "# dataframe5 = dataframe4.groupby(SCENARIO_NAME).agg(F.max('MAX_ALTITUDE').alias(\"MAX_ALTITUDE_SCN\"), F.min('MIN_ALTITUDE').alias(\"MIN_ALTITUDE_SCN\"))\n",
    "# dataframe5.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "def get_coordinates_distance(origin_latitude: float, origin_longitude: float,\n",
    "                             destination_latitude: float, destination_longitude: float) -> float:\n",
    "    \"\"\" Calculates the distance in meters between two world coordinates.\n",
    "\n",
    "    :param origin_latitude: origin latitude point.\n",
    "    :param origin_longitude: origin longitude point.\n",
    "    :param destination_latitude: destination latitude point.\n",
    "    :param destination_longitude: destination longitude point.\n",
    "    :return: distance in meters.\n",
    "    \"\"\"\n",
    "    origin_tuple = (origin_latitude, origin_longitude)\n",
    "    destination_tuple = (destination_latitude, destination_longitude)\n",
    "    # TODO: direct distance calculation (in meters) between two points, is this approach correct?\n",
    "    return geopy.distance.distance(origin_tuple, destination_tuple).m\n",
    "\n",
    "\n",
    "@udf\n",
    "def in_circle (x_center, y_center, x, y, radius):\n",
    "    return get_coordinates_distance(x_center, y_center, x, y) <= radius\n",
    "\n",
    "@udf(\"double\")\n",
    "def great_circle_udf(x, y):\n",
    "    return great_circle(x, y).kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(settings.x_center)\n",
    "print(settings.time_roi)\n",
    "print(settings.radius_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadEnv3points(geojson):\n",
    "    return gpd.read_file(geojson)[0:10] #only first 100 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"env3_points.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in df_points.iterrows():\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENV3\n",
    "dataframe3 = input_dataframes[REG_LOG_PREFIX]\n",
    "udf_func = udf(great_circle_udf,DoubleType()) #Creating a 'User Defined Function' to calculate distance between two points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENV3\n",
    "dataframe3 = input_dataframes[REG_LOG_PREFIX]\n",
    "\n",
    "#dataframe3.printSchema() \n",
    "#dataframe3.show()\n",
    "df_points = loadEnv3points(settings.geojson.path)\n",
    "\n",
    "for i,(x, y) in enumerate(zip(df_points.geometry.x, df_points.geometry.y)):\n",
    "    point = struct(lit(y), lit(x))\n",
    "    \n",
    "    aux_dataframe = dataframe3.filter(col(SIMULATION_TIME) == settings.env3.time_roi)\n",
    "    aux_dataframe = aux_dataframe.withColumn(\"distance\", great_circle_udf(point, struct(col(LATITUDE), col(LONGITUDE))))\n",
    "    aux_dataframe = aux_dataframe.filter((col(\"distance\") <= 16))\n",
    "    aux_dataframe = aux_dataframe.withColumn(\"sound_intensity\", 1/(pow((col(\"distance\")/settings.flight_altitude.lowest), 2)))\n",
    "    aux_dataframe = aux_dataframe.groupby(SCENARIO_NAME).agg(sum(\"sound_intensity\").alias(f\"ENV3_p{i}\"))\n",
    "    \n",
    "    \n",
    "    if(i==0):\n",
    "        final_dataframe = aux_dataframe\n",
    "    else:\n",
    "        final_dataframe = final_dataframe.join(aux_dataframe, SCENARIO_NAME)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "point = struct(lit(x_center), lit(y_center))\n",
    "udf_func = udf(great_circle_udf,DoubleType()) #Creating a 'User Defined Function' to calculate distance between two points.\n",
    "dataframe3 = dataframe3.withColumn(\"distance\", udf_func(point, struct(col(LATITUDE), col(LONGITUDE)))).filter((col(\"distance\") <= radius_roi) & (col(ALTITUDE)<= altitude_roi) & (col(SIMULATION_TIME) == time_roi)) #Creating column \"distance\" based on function 'get_distance'\n",
    "#dataframe3 = dataframe3.withColumn(\"noise_level\", 10*log(1/pow(col(\"distance\"),2)))\n",
    "dataframe3 = dataframe3.withColumn(\"noise_level\", log10(1/pow(col(\"distance\"),2)))\n",
    "dataframe3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe3.groupBy(SCENARIO_NAME).agg(sum(\"noise_level\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dataframe = input_dataframes[REG_LOG_PREFIX]\n",
    "\n",
    "point = struct(lit(settings.x_center), lit(settings.y_center))\n",
    "\n",
    "# TODO: ? Define formula for the sound depending on the distance to the point.\n",
    "# TODO: ? How many points and how to define.\n",
    "return dataframe.filter(col(SIMULATION_TIME) == settings.time_roi) \\\n",
    "    .withColumn(\"distance\", great_circle_udf(point, struct(col(LATITUDE), col(LONGITUDE)))) \\\n",
    "    .filter((col(\"distance\") <= settings.radius_roi) & (col(ALTITUDE) <= settings.altitude_roi)) \\\n",
    "    .withColumn(\"noise_level\", log10(1 / pow(col(\"distance\"), 2))) \\\n",
    "    .groupBy(SCENARIO_NAME).agg(sum(\"noise_level\").alias(ENV3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
